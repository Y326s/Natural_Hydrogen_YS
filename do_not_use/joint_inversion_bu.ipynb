{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "import pandas as pd\n",
    "import time\n",
    "import h5py\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "import discretize\n",
    "from discretize import TensorMesh\n",
    "from discretize.utils import active_from_xyz\n",
    "from SimPEG.potential_fields import gravity, magnetics\n",
    "from SimPEG import (\n",
    "    maps,\n",
    "    data,\n",
    "    inverse_problem,\n",
    "    data_misfit,\n",
    "    regularization,\n",
    "    optimization,\n",
    "    directives,\n",
    "    inversion,\n",
    "    utils,\n",
    ")\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Timestamp & Folder name\n",
    "\n",
    "# Get the current time in UTC\n",
    "now_utc = datetime.now(timezone.utc)\n",
    "# Define the UTC-5 offset\n",
    "utc_offset = timedelta(hours=-5)\n",
    "# Adjust the current time to UTC-5\n",
    "now_utc_minus_5 = now_utc + utc_offset\n",
    "# Format the time string\n",
    "timestamp = now_utc_minus_5.strftime(\"%m%d%y_%H%M%S\")\n",
    "\n",
    "mesh_name = \"mesh_joint_Hannah_exfine\"\n",
    "folder_name = mesh_name + \"_\" + timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir_list = [\"./temp_inv_out/\",\n",
    "              \"./temp_inv_out/\" + folder_name + \"/\",\n",
    "              \"./temp_inv_out/\" + folder_name + \"/saved_model/\",\n",
    "              \"./temp_inv_out/\" + folder_name + \"/saved_data/\"\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./temp_inv_out/ already exists! Skip creating this directory.\n",
      "Directory ./temp_inv_out/mesh_joint_Hannah_exfine_071725_035930/ created.\n",
      "Directory ./temp_inv_out/mesh_joint_Hannah_exfine_071725_035930/saved_model/ created.\n",
      "Directory ./temp_inv_out/mesh_joint_Hannah_exfine_071725_035930/saved_data/ created.\n"
     ]
    }
   ],
   "source": [
    "for dirs in mkdir_list:\n",
    "    if os.path.exists(dirs):\n",
    "        print(\"{0:s} already exists! Skip creating this directory.\".format(dirs))\n",
    "    else:\n",
    "        os.mkdir(dirs)\n",
    "        print(\"Directory {0:s} created.\".format(dirs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Directory\n",
    "## Read mesh\n",
    "mesh = TensorMesh._readUBC_3DMesh(\"./mesh/\" + mesh_name + \".txt\")\n",
    "mesh_rm = TensorMesh._readUBC_3DMesh(\"./mesh/\" + mesh_name + \"_rm.txt\")\n",
    "select_region = [510000, 535000, 4290000, 4320000]  # min_east, max_east, min_north, max_north\n",
    "xpad = 6\n",
    "ypad = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adjustable parameters\n",
    "\n",
    "magDSrate = 10\n",
    "std_grv = 0.25  # mGal\n",
    "std_mag = 10  # nT \n",
    "(grv_lb, mag_lb, grv_ub, mag_ub) = (-10.0, -10.0, 10.0, 10.0)\n",
    "\n",
    "grv_alpha_s = 20  # ~~~~~~~~~\n",
    "grv_alpha_x = 1\n",
    "grv_alpha_y = 1\n",
    "grv_alpha_z = 1\n",
    "mag_alpha_s = 10  # ~~~~~~~~~\n",
    "mag_alpha_x = 1\n",
    "mag_alpha_y = 1\n",
    "mag_alpha_z = 1\n",
    "\n",
    "reg_grv_norm = [1,2,2,2]  # ~~~~~~~~~\n",
    "reg_mag_norm = [1,2,2,2]  # ~~~~~~~~~\n",
    "# reg_grv_norm = [0,0,0,0]  # ~~~~~~~~~\n",
    "# reg_mag_norm = [0,0,0,0]  # ~~~~~~~~~\n",
    "\n",
    "maxGNCG = 100  # ~~~~~~~~~\n",
    "maxLS = 10\n",
    "maxCG = 1000\n",
    "tolCG = 1e-2\n",
    "tolX = 1e-2\n",
    "maxIRLSiter = 100  # ~~~~~~~~~\n",
    "IRLSstart = 5e4\n",
    "IRLS_mindelta = 1e-2\n",
    "IRLSbeta_tol = 1e-2\n",
    "\n",
    "beta0_ratio = 10\n",
    "betacool = 1.1\n",
    "\n",
    "CGlambda = 1e12  # weight for coupling term  # ~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load topography data\n",
    "df_topo = pd.read_csv(\"./data/Cali_topo_meter_m12315m12130_3840.csv\", names=[\"easting\", \"northing\", \"topo\"])  # TFMA: total field magnetic anomaly [nT]\n",
    "easting_topo_raw = np.array(df_topo['easting'])\n",
    "northing_topo_raw = np.array(df_topo['northing'])\n",
    "topo_raw = np.array(df_topo['topo'])\n",
    "\n",
    "select_index_topo = np.where(\n",
    "    (easting_topo_raw>select_region[0]-30000) &\n",
    "    (easting_topo_raw<select_region[1]+30000) &\n",
    "    (northing_topo_raw>select_region[2]-30000) &\n",
    "    (northing_topo_raw<select_region[3]+30000))[0]\n",
    "easting_topo = easting_topo_raw[select_index_topo]\n",
    "northing_topo = northing_topo_raw[select_index_topo]\n",
    "topo = topo_raw[select_index_topo]\n",
    "\n",
    "topo_xyz = np.zeros((easting_topo.shape[0], 3))\n",
    "topo_xyz[:, 0] = easting_topo\n",
    "topo_xyz[:, 1] = northing_topo\n",
    "topo_xyz[:, 2] = topo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load gravity data\n",
    "df_grv = pd.read_csv(\"./data/Mitchell_2022_CLVF_Gravity-main/groundGrav_Combined_zEllipsoid_Full.csv\")\n",
    "\n",
    "easting_grv_raw = np.array(df_grv['xWGS84_UTM10N'])\n",
    "northing_grv_raw = np.array(df_grv['yWGS84_UTM10N'])\n",
    "elevation_grv_raw = np.array(df_grv['zWGS84'])\n",
    "iso_grv_raw = np.array(df_grv['ISO'])\n",
    "\n",
    "select_index = np.where((easting_grv_raw>select_region[0]) & (easting_grv_raw<select_region[1]) & (northing_grv_raw>select_region[2]) & (northing_grv_raw<select_region[3]))[0]\n",
    "\n",
    "easting_grv = easting_grv_raw[select_index]\n",
    "northing_grv = northing_grv_raw[select_index]\n",
    "elevation_grv = elevation_grv_raw[select_index]\n",
    "iso_grv = iso_grv_raw[select_index]\n",
    "\n",
    "data_grv_ori = np.zeros((easting_grv.shape[0], 4))\n",
    "data_grv_ori[:, 0] = easting_grv\n",
    "data_grv_ori[:, 1] = northing_grv\n",
    "data_grv_ori[:, 2] = elevation_grv\n",
    "data_grv_ori[:, 3] = iso_grv  # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "data_grv = np.zeros((easting_grv.shape[0], 4))\n",
    "data_grv[:, 0] = easting_grv\n",
    "data_grv[:, 1] = northing_grv\n",
    "data_grv[:, 2] = elevation_grv\n",
    "data_grv[:, 3] = (-1) * iso_grv  # Considering SimPEG is using a opposite +z direction (+z upwards in SimPEG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load magnetic data\n",
    "df_mag = pd.read_csv(\"./data/mag_grid_meter_NAD27.csv\")  # TFMA: total field magnetic anomaly [nT]\n",
    "\n",
    "easting_mag_raw = np.array(df_mag['easting'])\n",
    "northing_mag_raw = np.array(df_mag['northing'])\n",
    "tfma_mag_raw = np.array(df_mag['TFMA'])\n",
    "\n",
    "select_index = np.where((easting_mag_raw>select_region[0]) & (easting_mag_raw<select_region[1]) & (northing_mag_raw>select_region[2]) & (northing_mag_raw<select_region[3]))[0]\n",
    "\n",
    "easting_mag = easting_mag_raw[select_index]\n",
    "northing_mag = northing_mag_raw[select_index]\n",
    "tfma_mag = tfma_mag_raw[select_index]\n",
    "\n",
    "\n",
    "flight_h = 1000 / 3.2808399\n",
    "data_mag_ori = np.zeros((easting_mag.shape[0], 4))\n",
    "data_mag_ori[:, 0] = easting_mag\n",
    "data_mag_ori[:, 1] = northing_mag\n",
    "data_mag_ori[:, 3] = tfma_mag\n",
    "# Intepolate aeromagnetic receiver elevation according to topo data\n",
    "interp_rec = griddata(topo_xyz[:, 0:2], topo_xyz[:, 2], data_mag_ori[:, 0:2], method='linear')\n",
    "data_mag_ori[:, 2] = interp_rec + flight_h\n",
    "\n",
    "if np.sum(np.isnan(data_mag_ori[:, 2])) > 0:\n",
    "    print(\"NaNs exist in the interpolated receiver elevation!\")\n",
    "    nan_ind = np.argwhere(np.isnan(data_mag_ori[:, 2]))\n",
    "    data_mag_ori[nan_ind, 2] = 1200\n",
    "\n",
    "\n",
    "data_mag_temp = data_mag_ori.copy()\n",
    "data_mag = data_mag_temp[::magDSrate,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the Survey\n",
    "\n",
    "# Define the receivers. The data consist of vertical gravity anomaly measurements.\n",
    "# The set of receivers must be defined as a list.\n",
    "receiver_grv = gravity.receivers.Point(data_grv[:,0:3], components=\"gz\")\n",
    "\n",
    "# Define the source field and survey for gravity data\n",
    "source_field_grv = gravity.sources.SourceField(receiver_list=[receiver_grv])\n",
    "survey_grv = gravity.survey.Survey(source_field_grv)\n",
    "\n",
    "\n",
    "# Define the component(s) of the field we want to simulate as a list of strings.\n",
    "# Here we simulation total magnetic intensity data.\n",
    "# Use the observation locations and components to define the receivers. To\n",
    "# simulate data, the receivers must be defined as a list.\n",
    "receiver_mag = magnetics.receivers.Point(data_mag[:,0:3], components=\"tmi\")\n",
    "\n",
    "# Define the inducing field H0 = (intensity [nT], inclination [deg], declination [deg])\n",
    "inclination = 62\n",
    "declination = 15\n",
    "strength = 50686\n",
    "\n",
    "# Define the source field and survey for gravity data\n",
    "source_field_mag = magnetics.sources.UniformBackgroundField(\n",
    "    receiver_list=[receiver_mag],\n",
    "    amplitude=strength,\n",
    "    inclination=inclination,\n",
    "    declination=declination,\n",
    ")\n",
    "survey_mag = magnetics.survey.Survey(source_field_mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the Data\n",
    "maximum_anomaly_grv = np.max(np.abs(data_grv[:,3]))\n",
    "uncertainties_grv = std_grv * np.ones(np.shape(data_grv[:,3]))\n",
    "\n",
    "maximum_anomaly_mag = np.max(np.abs(data_mag[:,3]))\n",
    "uncertainties_mag = std_mag * np.ones(np.shape(data_mag[:,3]))\n",
    "\n",
    "data_object_grv = data.Data(\n",
    "    survey_grv, dobs=data_grv[:,3], standard_deviation=uncertainties_grv\n",
    ")\n",
    "data_object_mag = data.Data(\n",
    "    survey_mag, dobs=data_mag[:,3], standard_deviation=uncertainties_mag\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Starting/Reference Model and Mapping on Tensor Mesh\n",
    "\n",
    "# Define density contrast values for each unit in g/cc.\n",
    "background_dens, background_susc = 1e-6, 1e-6\n",
    "\n",
    "# Find the indicies of the active cells in forward model (ones below surface)\n",
    "ind_active = active_from_xyz(mesh, topo_xyz)\n",
    "\n",
    "# Define mapping from model to active cells\n",
    "nC = int(ind_active.sum())\n",
    "model_map = maps.IdentityMap(nP=nC)  # model consists of a value for each active cell\n",
    "\n",
    "# Create Wires Map that maps from stacked models to individual model components\n",
    "# m1 refers to density model, m2 refers to susceptibility\n",
    "wires = maps.Wires((\"density\", nC), (\"susceptibility\", nC))\n",
    "\n",
    "# Define and plot starting model\n",
    "starting_model = np.r_[background_dens * np.ones(nC), background_susc * np.ones(nC)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "Pre-processed isostatic gravity anomaly, total field magnetic anomaly, topography, and SimPEG active mesh cells are saved in ./temp_inv_out/mesh_joint_Hannah_exfine_071725_035930/saved_data directory\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "np.save(\"./temp_inv_out/\" + folder_name + \"/saved_data/data_grv_ori.npy\",data_grv_ori)\n",
    "np.save(\"./temp_inv_out/\" + folder_name + \"/saved_data/data_mag_ori.npy\",data_mag_ori)\n",
    "np.save(\"./temp_inv_out/\" + folder_name + \"/saved_data/topo_xyz.npy\",topo_xyz)\n",
    "np.save(\"./temp_inv_out/\" + folder_name + \"/saved_data/ind_active.npy\",ind_active)\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"Pre-processed isostatic gravity anomaly, total field magnetic anomaly, topography, and SimPEG active mesh cells are saved in ./temp_inv_out/{0:s}/saved_data directory\".format(folder_name))\n",
    "print(\"---------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the Physics\n",
    "\n",
    "simulation_grv = gravity.simulation.Simulation3DIntegral(\n",
    "    survey=survey_grv,\n",
    "    mesh=mesh,\n",
    "    rhoMap=wires.density,\n",
    "    ind_active=ind_active,\n",
    "    engine=\"choclo\",\n",
    ")\n",
    "\n",
    "simulation_mag = magnetics.simulation.Simulation3DIntegral(\n",
    "    survey=survey_mag,\n",
    "    mesh=mesh,\n",
    "    model_type=\"scalar\",\n",
    "    chiMap=wires.susceptibility,\n",
    "    ind_active=ind_active,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the Inverse Problem\n",
    "\n",
    "\n",
    "# Define the data misfit. Here the data misfit is the L2 norm of the weighted\n",
    "# residual between the observed data and the data predicted for a given model.\n",
    "# Within the data misfit, the residual between predicted and observed data are\n",
    "# normalized by the data's standard deviation.\n",
    "dmis_grv = data_misfit.L2DataMisfit(data=data_object_grv, simulation=simulation_grv)\n",
    "dmis_mag = data_misfit.L2DataMisfit(data=data_object_mag, simulation=simulation_mag)\n",
    "\n",
    "# Define the regularization (model objective function)\n",
    "reg_grv = regularization.Sparse(\n",
    "    mesh, active_cells=ind_active, mapping=wires.density,\n",
    "    gradient_type = \"components\"\n",
    ")\n",
    "reg_mag = regularization.Sparse(\n",
    "    mesh, active_cells=ind_active, mapping=wires.susceptibility,\n",
    "    gradient_type = \"components\"\n",
    ")\n",
    "\n",
    "# Norms for regularization terms\n",
    "reg_grv.norms = reg_grv_norm  # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "reg_mag.norms = reg_mag_norm\n",
    "\n",
    "# Weights for regularization terms\n",
    "reg_grv.alpha_s = grv_alpha_s\n",
    "reg_grv.alpha_x = grv_alpha_x\n",
    "reg_grv.alpha_y = grv_alpha_y\n",
    "reg_grv.alpha_z = grv_alpha_z\n",
    "reg_mag.alpha_s = mag_alpha_s\n",
    "reg_mag.alpha_x = mag_alpha_x\n",
    "reg_mag.alpha_y = mag_alpha_y\n",
    "reg_mag.alpha_z = mag_alpha_z\n",
    "\n",
    "# Define the coupling term to connect two different physical property models\n",
    "lamda = CGlambda # weight for coupling term\n",
    "cross_grad = regularization.CrossGradient(mesh, wires, active_cells=ind_active)\n",
    "\n",
    "# Combine data misfit and regularization\n",
    "dmis = dmis_grv + dmis_mag\n",
    "reg = reg_grv + reg_mag + lamda * cross_grad\n",
    "\n",
    "# # Define how the optimization problem is solved. Here we will use a projected\n",
    "# # Gauss-Newton approach that employs the conjugate gradient solver.\n",
    "opt = optimization.ProjectedGNCG(\n",
    "    maxIter=maxGNCG,\n",
    "    lower=np.concatenate([grv_lb * np.ones(nC), mag_lb * np.ones(nC)], 0),\n",
    "    upper=np.concatenate([grv_ub * np.ones(nC), mag_ub * np.ones(nC)], 0),\n",
    "    maxIterLS=maxLS,\n",
    "    maxIterCG=maxCG,\n",
    "    tolCG=tolCG,\n",
    "    tolX=tolX,\n",
    ")\n",
    "\n",
    "# Here we define the inverse problem that is to be solved\n",
    "inv_prob = inverse_problem.BaseInvProblem(dmis, reg, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a starting value for the trade-off parameter (beta) between the data\n",
    "# misfit and the regularization.\n",
    "starting_beta = directives.PairedBetaEstimate_ByEig(beta0_ratio=beta0_ratio)\n",
    "# starting_beta.n_pw_iter = 10\n",
    "\n",
    "# Defines the directives for the IRLS regularization. This includes setting\n",
    "# the cooling schedule for the trade-off parameter.\n",
    "update_IRLS = directives.Update_IRLS(\n",
    "    f_min_change=IRLS_mindelta,\n",
    "    max_irls_iterations=maxIRLSiter,\n",
    "    # coolEpsFact=1.5,\n",
    "    beta_tol=IRLSbeta_tol,\n",
    "    verbose=True\n",
    ")\n",
    "update_IRLS.start = IRLSstart\n",
    "\n",
    "# Defining the fractional decrease in beta and the number of Gauss-Newton solves\n",
    "# for each beta value.\n",
    "beta_schedule = directives.PairedBetaSchedule(cooling_factor=betacool, cooling_rate=1)\n",
    "joint_inv_dir = directives.SimilarityMeasureInversionDirective()\n",
    "stopping = directives.MovingAndMultiTargetStopping(tol=1e-6)\n",
    "sensitivity_weights = directives.UpdateSensitivityWeights(every_iteration=False)\n",
    "\n",
    "# Updating the preconditionner if it is model dependent.\n",
    "update_jacobi = directives.UpdatePreconditioner()\n",
    "\n",
    "save_output = directives.SimilarityMeasureSaveOutputEveryIteration(directory=\"./temp_inv_out/\" + folder_name + \"/saved_model/\", name='Output')\n",
    "save_model = directives.SaveModelEveryIteration(directory=\"./temp_inv_out/\" + folder_name + \"/saved_model/\", name='InversionModel')\n",
    "\n",
    "# The directives are defined as a list.\n",
    "directives_list = [  # ##################################################################################\n",
    "    joint_inv_dir,\n",
    "    sensitivity_weights,  # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    starting_beta,  # ~\n",
    "    # stopping,\n",
    "    beta_schedule,\n",
    "    update_IRLS,  # ~\n",
    "    save_output,  # ~\n",
    "    save_model,\n",
    "    update_jacobi,  # ~\n",
    "    # target_misfit\n",
    "]\n",
    "\n",
    "# Here we combine the inverse problem and the set of directives\n",
    "inv = inversion.BaseInversion(inv_prob, directives_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic_inv = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimPEG.InvProblem will set Regularization.reference_model to m0.\n",
      "SimPEG.InvProblem will set Regularization.reference_model to m0.\n",
      "SimPEG.InvProblem will set Regularization.reference_model to m0.\n",
      "\n",
      "                    SimPEG.InvProblem is setting bfgsH0 to the inverse of the eval2Deriv.\n",
      "                    ***Done using the default solver SolverLU and no solver_opts.***\n",
      "                    \n",
      "CrossGradientSaveOutputEveryIteration will save your inversion progress as: '###-Output-2025-07-17-09-13.txt'\n",
      "SimPEG.SaveModelEveryIteration will save your models as: './temp_inv_out/mesh_joint_Hannah_exfine_071725_035930/saved_model//###-InversionModel-2025-07-17-09-13.npy'\n",
      "model has any nan: 0\n",
      "============================================================ Projected GNCG ============================================================\n",
      "  #            betas             lambda      f               phi_d                     phi_m            phi_sim    iterCG    Comment   \n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "x0 has any nan: 0\n",
      "   0  ['2.82e-02', '1.92e-02']  1.00e+12  3.65e+06             []                        []             0.00e+00      0                \n",
      "   1  ['2.56e-02', '1.75e-02']  1.00e+12  1.39e+06  ['8.80e+05', '1.31e+05']  ['2.50e+07', '6.14e+06']  1.23e-09     16                \n",
      "   2  ['2.33e-02', '1.59e-02']  1.00e+12  8.45e+05  ['4.59e+05', '6.85e+04']  ['4.69e+07', '1.09e+07']  1.13e-09    1000    Skip BFGS  \n",
      "   3  ['2.12e-02', '1.45e-02']  1.00e+12  4.93e+05  ['2.40e+05', '3.26e+04']  ['7.18e+07', '1.69e+07']  4.05e-09    1000    Skip BFGS  \n",
      "   4  ['1.92e-02', '1.31e-02']  1.00e+12  2.83e+05  ['1.29e+05', '1.50e+04']  ['9.96e+07', '2.30e+07']  9.79e-09    1000    Skip BFGS  \n",
      "   5  ['1.75e-02', '1.19e-02']  1.00e+12  1.60e+05  ['6.90e+04', '6.78e+03']  ['1.32e+08', '2.92e+07']  2.11e-08    1000    Skip BFGS  \n",
      "Reached starting chifact with l2-norm regularization: Start IRLS steps...\n",
      "irls_threshold 0.11909675359416567\n",
      "irls_threshold 0.04222492020894919\n",
      "   6  ['1.59e-02', '1.09e-02']  1.00e+12  1.07e+05  ['3.70e+04', '3.48e+03']  ['1.70e+08', '3.46e+07']  3.84e-08    1000    Skip BFGS  \n",
      "   7  ['1.45e-02', '9.87e-03']  1.00e+12  6.87e+04  ['2.45e+04', '2.53e+03']  ['2.65e+08', '5.44e+07']  5.86e-08    1000    Skip BFGS  \n",
      "   8  ['1.31e-02', '1.00e-02']  1.00e+12  4.97e+04  ['1.52e+04', '1.85e+03']  ['4.51e+08', '7.63e+07']  1.11e-07    1000    Skip BFGS  \n",
      "   9  ['1.19e-02', '1.13e-02']  1.00e+12  3.87e+04  ['1.03e+04', '1.66e+03']  ['8.19e+08', '1.37e+08']  1.84e-07    1000    Skip BFGS  \n",
      "  10  ['1.09e-02', '1.37e-02']  1.00e+12  2.96e+04  ['7.07e+03', '1.54e+03']  ['1.46e+09', '2.45e+08']  3.05e-07    1000    Skip BFGS  \n",
      "  11  ['9.87e-03', '1.73e-02']  1.00e+12  2.89e+04  ['4.61e+03', '1.49e+03']  ['2.24e+09', '4.20e+08']  4.89e-07    1000    Skip BFGS  \n",
      "  12  ['8.97e-03', '2.18e-02']  1.00e+12  2.99e+04  ['4.10e+03', '1.49e+03']  ['4.14e+09', '6.52e+08']  6.68e-07    1000    Skip BFGS  \n",
      "  13  ['8.16e-03', '2.77e-02']  1.00e+12  2.74e+04  ['4.25e+03', '1.48e+03']  ['7.81e+09', '9.34e+08']  9.08e-07    1000               \n",
      "  14  ['7.42e-03', '3.69e-02']  1.00e+12  2.04e+04  ['3.80e+03', '1.39e+03']  ['1.31e+10', '1.19e+09']  9.77e-07    1000               \n",
      "  15  ['6.74e-03', '4.92e-02']  1.00e+12  1.94e+04  ['2.75e+03', '1.32e+03']  ['1.51e+10', '1.39e+09']  1.54e-06    1000               \n",
      "  16  ['6.13e-03', '6.56e-02']  1.00e+12  1.82e+04  ['2.57e+03', '1.34e+03']  ['2.20e+10', '1.62e+09']  1.79e-06    1000               \n",
      "  17  ['5.57e-03', '8.75e-02']  1.00e+12  1.65e+04  ['2.20e+03', '1.34e+03']  ['2.99e+10', '1.88e+09']  2.19e-06    1000               \n",
      "  18  ['5.06e-03', '1.10e-01']  1.00e+12  1.56e+04  ['1.86e+03', '1.49e+03']  ['3.39e+10', '2.12e+09']  2.83e-06    1000               \n",
      "  19  ['4.60e-03', '1.42e-01']  1.00e+12  1.52e+04  ['1.60e+03', '1.46e+03']  ['4.21e+10', '2.34e+09']  3.60e-06    1000               \n",
      "  20  ['4.19e-03', '1.63e-01']  1.00e+12  1.32e+04  ['1.47e+03', '1.63e+03']  ['5.14e+10', '2.42e+09']  4.10e-06    1000               \n",
      "  21  ['3.81e-03', '2.00e-01']  1.00e+12  1.26e+04  ['1.20e+03', '1.53e+03']  ['5.34e+10', '2.53e+09']  5.49e-06    1000               \n",
      "  22  ['3.46e-03', '2.23e-01']  1.00e+12  1.15e+04  ['1.02e+03', '1.68e+03']  ['5.40e+10', '2.54e+09']  6.44e-06    1000               \n",
      "  23  ['3.14e-03', '2.65e-01']  1.00e+12  1.79e+04  ['8.41e+02', '1.58e+03']  ['5.53e+10', '2.62e+09']  7.87e-06    1000               \n",
      "  24  ['2.86e-03', '2.41e-01']  1.00e+12  1.31e+04  ['8.29e+02', '2.60e+03']  ['5.46e+10', '2.35e+09']  7.18e-06    1000               \n",
      "  25  ['2.60e-03', '2.20e-01']  1.00e+12  1.07e+04  ['7.58e+02', '2.06e+03']  ['5.56e+10', '2.51e+09']  8.17e-06    1000               \n",
      "  26  ['2.63e-03', '2.37e-01']  1.00e+12  1.89e+04  ['6.61e+02', '1.73e+03']  ['5.64e+10', '2.74e+09']  9.27e-06    1000    Skip BFGS  \n",
      "  27  ['2.68e-03', '2.16e-01']  1.00e+12  1.48e+04  ['6.56e+02', '3.03e+03']  ['5.58e+10', '3.05e+09']  8.47e-06    1000               \n",
      "  28  ['2.98e-03', '1.96e-01']  1.00e+12  1.22e+04  ['6.02e+02', '2.68e+03']  ['5.65e+10', '3.67e+09']  9.80e-06    1000               \n",
      "  29  ['3.69e-03', '1.78e-01']  1.00e+12  1.06e+04  ['5.41e+02', '2.21e+03']  ['5.69e+10', '4.30e+09']  1.07e-05    1000               \n",
      "  30  ['4.92e-03', '1.77e-01']  1.00e+12  1.61e+04  ['4.90e+02', '1.89e+03']  ['5.70e+10', '4.77e+09']  1.17e-05    1000    Skip BFGS  \n",
      "  31  ['6.42e-03', '1.61e-01']  1.00e+12  1.37e+04  ['5.12e+02', '2.57e+03']  ['5.61e+10', '4.56e+09']  1.07e-05    1000               \n",
      "  32  ['8.33e-03', '1.47e-01']  1.00e+12  1.23e+04  ['5.16e+02', '2.21e+03']  ['5.60e+10', '5.06e+09']  1.13e-05    1000               \n",
      "  33  ['1.06e-02', '1.50e-01']  1.00e+12  1.91e+04  ['5.24e+02', '1.84e+03']  ['5.55e+10', '5.38e+09']  1.21e-05    1000               \n",
      "  34  ['1.02e-02', '1.36e-01']  1.00e+12  1.48e+04  ['6.97e+02', '2.48e+03']  ['5.36e+10', '4.87e+09']  1.07e-05    1000               \n",
      "  35  ['1.08e-02', '1.24e-01']  1.00e+12  1.25e+04  ['6.31e+02', '2.05e+03']  ['5.49e+10', '5.30e+09']  1.16e-05    1000               \n",
      "  36  ['1.18e-02', '1.38e-01']  1.00e+12  1.92e+04  ['6.17e+02', '1.69e+03']  ['5.45e+10', '5.50e+09']  1.24e-05    1000    Skip BFGS  \n",
      "  37  ['1.07e-02', '1.26e-01']  1.00e+12  1.48e+04  ['7.64e+02', '2.30e+03']  ['5.29e+10', '4.83e+09']  1.97e-05    1000               \n",
      "  38  ['9.79e-03', '1.14e-01']  1.00e+12  1.16e+04  ['7.30e+02', '2.13e+03']  ['5.39e+10', '5.05e+09']  1.17e-05    1000               \n",
      "  39  ['1.02e-02', '1.28e-01']  1.00e+12  1.73e+04  ['6.41e+02', '1.68e+03']  ['5.45e+10', '5.37e+09']  1.24e-05    1000    Skip BFGS  \n",
      "  40  ['9.65e-03', '1.16e-01']  1.00e+12  1.40e+04  ['7.09e+02', '2.12e+03']  ['5.34e+10', '4.78e+09']  1.11e-05    1000               \n",
      "  41  ['9.44e-03', '1.18e-01']  1.00e+12  1.36e+04  ['6.83e+02', '1.85e+03']  ['5.38e+10', '5.11e+09']  1.17e-05    1000               \n",
      "  42  ['9.29e-03', '1.21e-01']  1.00e+12  1.92e+04  ['6.80e+02', '1.83e+03']  ['5.36e+10', '4.91e+09']  1.16e-05    1000               \n",
      "  43  ['8.45e-03', '1.10e-01']  1.00e+12  1.48e+04  ['7.53e+02', '2.32e+03']  ['5.29e+10', '4.52e+09']  1.18e-05    1000               \n",
      "  44  ['7.82e-03', '1.03e-01']  1.00e+12  1.20e+04  ['7.22e+02', '1.99e+03']  ['5.35e+10', '4.87e+09']  1.10e-05    1000               \n",
      "Minimum decrease in regularization.End of IRLS\n",
      "------------------------- STOP! -------------------------\n",
      "0 : maxIter   =     100    <= iter          =     45\n",
      "------------------------- DONE! -------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run inversion\n",
    "recovered_model = inv.run(starting_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inversion runtime is: 3.19 [h]\n"
     ]
    }
   ],
   "source": [
    "print(\"The inversion runtime is: {0:.2f} [h]\".format((time.time()-tic_inv)/3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "Direct inversion output (both models) saved as ./temp_inv_out/mesh_joint_Hannah_exfine_071725_035930/saved_model/recovered_model.npy\n",
      "Recovered data saved as ./temp_inv_out/mesh_joint_Hannah_exfine_071725_035930/saved_model/inv_prob.npy\n"
     ]
    }
   ],
   "source": [
    "np.save(\"./temp_inv_out/\" + folder_name + \"/saved_model/recovered_model.npy\", recovered_model)\n",
    "np.save(\"./temp_inv_out/\" + folder_name + \"/saved_model/inv_prob.npy\", inv_prob.dpred)\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"Direct inversion output (both models) saved as ./temp_inv_out/{0:s}/saved_model/recovered_model.npy\".format(folder_name))\n",
    "print(\"Recovered data saved as ./temp_inv_out/{0:s}/saved_model/inv_prob.npy\".format(folder_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "Jointly inverted models (with padding cells) saved as ./temp_inv_out/mesh_joint_Hannah_exfine_071725_035930/saved_model/joint_dens_model_UBC.txt and joint_susc_model_UBC.txt\n"
     ]
    }
   ],
   "source": [
    "# Save inverted models (1D, with padding) in UBC format for geology differentiation. (Pad 0 for inactive cells)\n",
    "pad0_map = maps.InjectActiveCells(mesh, ind_active, 0)\n",
    "mesh.write_model_UBC(\"./temp_inv_out/\" + folder_name + \"/saved_model/joint_dens_model_UBC.txt\", pad0_map * (wires * recovered_model)[0])\n",
    "mesh.write_model_UBC(\"./temp_inv_out/\" + folder_name + \"/saved_model/joint_susc_model_UBC.txt\", pad0_map * (wires * recovered_model)[1])\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"Jointly inverted models (with padding cells) saved as ./temp_inv_out/{0:s}/saved_model/joint_dens_model_UBC.txt and joint_susc_model_UBC.txt\".format(folder_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inverted models in UBC format and created models without padding (1D)\n",
    "modelGD_dens = discretize.TensorMesh.read_model_UBC(mesh, file_name=\"./temp_inv_out/\" + folder_name + \"/saved_model/joint_dens_model_UBC.txt\")\n",
    "modelGD_susc = discretize.TensorMesh.read_model_UBC(mesh, file_name=\"./temp_inv_out/\" + folder_name + \"/saved_model/joint_susc_model_UBC.txt\")\n",
    "# modelDG_unit = discretize.TensorMesh.read_model_UBC(mesh_rm, file_name=\"./temp_inv_out/\" + folder_name + \"/GD/model_inpolygon.txt\")\n",
    "\n",
    "modelGD_dens_3d = np.reshape(\n",
    "    modelGD_dens, (mesh.shape_cells[0],mesh.shape_cells[1],mesh.shape_cells[2]), \n",
    "    order=\"F\"\n",
    "    )\n",
    "modelGD_susc_3d = np.reshape(\n",
    "    modelGD_susc, (mesh.shape_cells[0],mesh.shape_cells[1],mesh.shape_cells[2]), \n",
    "    order=\"F\"\n",
    "    )\n",
    "\n",
    "# remove padding cells\n",
    "modelGD_dens_rm = modelGD_dens_3d[\n",
    "    xpad:mesh.shape_cells[0]-xpad,\n",
    "    ypad:mesh.shape_cells[1]-ypad,\n",
    "    0:mesh.shape_cells[2] # 0 is deep part, mesh.shape_cells[2] is near surface layer\n",
    "    ]\n",
    "modelGD_dens_rm = discretize.utils.mkvc(modelGD_dens_rm)\n",
    "\n",
    "modelGD_susc_rm = modelGD_susc_3d[\n",
    "    xpad:mesh.shape_cells[0]-xpad,\n",
    "    ypad:mesh.shape_cells[1]-ypad,\n",
    "    0:mesh.shape_cells[2]\n",
    "    ]\n",
    "modelGD_susc_rm = discretize.utils.mkvc(modelGD_susc_rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "Jointly inverted models (without padding cells) saved as ./temp_inv_out/mesh_joint_Hannah_exfine_071725_035930/saved_model/joint_dens_model_rm_UBC.txt and joint_susc_model_rm_UBC.txt\n"
     ]
    }
   ],
   "source": [
    "# Save the inverted models without padding (1D) in UBC format\n",
    "mesh_rm.write_model_UBC(\"./temp_inv_out/\" + folder_name + \"/saved_model/joint_dens_model_rm_UBC.txt\", modelGD_dens_rm)\n",
    "mesh_rm.write_model_UBC(\"./temp_inv_out/\" + folder_name + \"/saved_model/joint_susc_model_rm_UBC.txt\", modelGD_susc_rm)\n",
    "\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"Jointly inverted models (without padding cells) saved as ./temp_inv_out/{0:s}/saved_model/joint_dens_model_rm_UBC.txt and joint_susc_model_rm_UBC.txt\".format(folder_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "Inversion parameters saved in ./temp_inv_out/mesh_joint_Hannah_exfine_071725_035930/saved_model/paras.h5\n"
     ]
    }
   ],
   "source": [
    "# Save other parameters\n",
    "with h5py.File(\"./temp_inv_out/\" + folder_name + \"/saved_model/paras.h5\", \"w\") as h5f:\n",
    "    h5f.create_dataset(\"core_zone\", data=np.array(select_region))\n",
    "    h5f.attrs[\"xpad\"] = xpad\n",
    "    h5f.attrs[\"ypad\"] = ypad\n",
    "    h5f.attrs[\"magDSrate\"] = magDSrate\n",
    "    h5f.attrs[\"std_grv\"] = std_grv\n",
    "    h5f.attrs[\"std_mag\"] = std_mag\n",
    "\n",
    "    h5f.create_dataset(\"inv_bound\", data=(grv_lb, mag_lb, grv_ub, mag_ub))\n",
    "    h5f.create_dataset(\"weight_grv\", data=(grv_alpha_s, grv_alpha_x, grv_alpha_y, grv_alpha_z))\n",
    "    h5f.create_dataset(\"weight_mag\", data=(mag_alpha_s, mag_alpha_x, mag_alpha_y, mag_alpha_z))\n",
    "    h5f.create_dataset(\"reg_grv_norm\", data=reg_grv_norm)\n",
    "    h5f.create_dataset(\"reg_mag_norm\", data=reg_mag_norm)\n",
    "    \n",
    "    h5f.attrs[\"maxGNCG\"] = maxGNCG\n",
    "    h5f.attrs[\"maxLS\"] = maxLS\n",
    "    h5f.attrs[\"maxCG\"] = maxCG\n",
    "    h5f.attrs[\"tolCG\"] = tolCG\n",
    "    h5f.attrs[\"tolX\"] = tolX\n",
    "    h5f.attrs[\"maxIRLSiter\"] = maxIRLSiter\n",
    "    h5f.attrs[\"IRLSstart\"] = IRLSstart\n",
    "    h5f.attrs[\"IRLS_mindelta\"] = IRLS_mindelta\n",
    "    h5f.attrs[\"IRLSbeta_tol\"] = IRLSbeta_tol\n",
    "    h5f.attrs[\"beta0_ratio\"] = beta0_ratio\n",
    "    h5f.attrs[\"betacool\"] = betacool\n",
    "    h5f.attrs[\"CGlambda\"] = CGlambda\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"Inversion parameters saved in ./temp_inv_out/{0:s}/saved_model/paras.h5\".format(folder_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "Please use the plot_results.ipynb with mesh name (mesh_joint_Hannah_exfine) and folder_name (mesh_joint_Hannah_exfine_071725_035930) to plot the data and results.\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------------------------\")\n",
    "print(\"Please use the plot_results.ipynb with mesh name ({0:s}) and folder_name ({1:s}) to plot the data and results.\".format(mesh_name, folder_name))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
